{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d450978a0fd1af",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30e6176e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.190218Z",
     "start_time": "2024-07-24T04:10:59.187252Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9ddfedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.410710Z",
     "start_time": "2024-07-24T04:10:59.307193Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b24df538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.423424Z",
     "start_time": "2024-07-24T04:10:59.414016Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42b90774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.727099Z",
     "start_time": "2024-07-24T04:10:59.425506Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_get_text(html_code):\n",
    "    soup = BeautifulSoup(html_code)\n",
    "    return soup.get_text().strip()\n",
    "question_cleaned = df['Question'].apply(my_get_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "390955e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.773534Z",
     "start_time": "2024-07-24T04:10:59.729942Z"
    }
   },
   "outputs": [],
   "source": [
    "df_noimage_mask = df[~df['Question'].str.contains(\"img\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a23b9a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:11:00.046959Z",
     "start_time": "2024-07-24T04:10:59.775004Z"
    }
   },
   "outputs": [],
   "source": [
    "question_cleaned_noimg = df_noimage_mask['Question'].apply(my_get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc49e8d27a9b58",
   "metadata": {},
   "source": [
    "\n",
    "#### Open Router Question Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4a0a66b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T03:27:22.164721Z",
     "start_time": "2024-07-26T03:27:22.136154Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "# api_key = \"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\"\n",
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b20be57969764df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:11:00.071411Z",
     "start_time": "2024-07-24T04:11:00.053792Z"
    }
   },
   "outputs": [],
   "source": [
    "df_50_question = question_cleaned_noimg.sample(n=50,random_state=1)\n",
    "df_50_question.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb03f21f9b31c7",
   "metadata": {},
   "source": [
    "#### API request for specific model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2169d96f4fcdd96b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T03:27:27.470661Z",
     "start_time": "2024-07-26T03:27:27.457686Z"
    }
   },
   "outputs": [],
   "source": [
    "def ask_question_open_router(question,model):\n",
    "    response = requests.post(\n",
    "  url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "  headers={\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"seed\": \"42\",\n",
    "  },\n",
    "  data=json.dumps({\n",
    "    \"model\": model, \n",
    "    \"messages\": [\n",
    "      {\"role\": \"user\", \"content\": question }\n",
    "    ]\n",
    "  })\n",
    ")\n",
    "    response_data = response.json()\n",
    "    messages = [choice['message']['content'] for choice in response_data['choices']]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers for google/gemini-pro...\n",
      "Generating answers for mistralai/mixtral-8x7b-instruct:nitro...\n",
      "Generating answers for mistralai/mistral-7b-instruct:nitro...\n",
      "Completed generating answers for all models.\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    # \"openai/gpt-3.5-turbo\",\n",
    "    # \"openai/gpt-4\",\n",
    "    # \"meta-llama/llama-2-70b-chat\",\n",
    "    # \"mistralai/mistral-7b-instruct\",\n",
    "    # \"anthropic/claude-3-opus\",\n",
    "    \"google/gemini-pro\",\n",
    "    \"mistralai/mixtral-8x7b-instruct:nitro\",\n",
    "    \"mistralai/mistral-7b-instruct:nitro\"\n",
    "]\n",
    "# Iterate through each model\n",
    "for model in models:\n",
    "    # Create an empty DataFrame to store the results for each model\n",
    "    result = pd.DataFrame(index=range(50), columns=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "    print(f\"Generating answers for {model}...\")\n",
    "\n",
    "    # Generate answers for Q1\n",
    "    for i in range(50):\n",
    "        question = (\"Based on the following multiple-choice question, generate three plausible distractors \"\n",
    "                    \"and one correct answer. Mark the correct answer with an (X), and no explanation \")+ df_50_question[i]\n",
    "        messages = ask_question_open_router(question, model)\n",
    "        result.at[i, 'Q1'] = messages[0]\n",
    "\n",
    "    # Evaluate if the question is unambiguous for Q2\n",
    "    for i in range(50):\n",
    "        question = \"Is the question an unambiguous exam question that has only one answer? \" + df_50_question[i]\n",
    "        messages = ask_question_open_router(question, model)\n",
    "        result.at[i, 'Q2'] = \"Y\" if \"YES\" in messages[0].upper() else \"N\"\n",
    "\n",
    "    # Rephrase ambiguous questions for Q3\n",
    "    for i in range(50):\n",
    "        if result.at[i, 'Q2'] == \"N\":\n",
    "            question = \"How would you rephrase the question to be unambiguous and suitable for a Multiple choice question on an exam? \" + df_50_question[i]\n",
    "            messages = ask_question_open_router(question, model)\n",
    "            result.at[i, 'Q3'] = messages[0]\n",
    "        else:\n",
    "            result.at[i, 'Q3'] = \"None\"\n",
    "\n",
    "    # Generate new answers for rephrased questions for Q4\n",
    "    for i in range(50):\n",
    "        if result.at[i, 'Q3'] != \"None\":\n",
    "            question = ((\"Based on the following multiple-choice question, generate three \"\n",
    "                        \"plausible distractors and one correct answer. Mark the correct answer with an (X), and no explanation \")+ df_50_question[i])\n",
    "            messages = ask_question_open_router(question, model)\n",
    "            result.at[i, 'Q4'] = messages[0]\n",
    "        else:\n",
    "            result.at[i, 'Q4'] = \"None\"\n",
    "\n",
    "    \n",
    "    file_path = os.path.join(output_dir, f\"{model.split('/')[1]}.xlsx\")\n",
    "    result.to_excel(file_path, index=False)\n",
    "\n",
    "    # Adjust column widths\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    for column in ws.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter  # Get the column letter\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if cell.value:\n",
    "                    max_length = max(max_length, len(str(cell.value)))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2) * 1.2  # Add some padding\n",
    "        ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "    for row in ws.iter_rows():\n",
    "        max_height = 0\n",
    "        for cell in row:\n",
    "            if cell.value:\n",
    "                lines = str(cell.value).split('\\n')\n",
    "                cell_height = len(lines) * 15  # Approximate row height per line\n",
    "                if cell_height > max_height:\n",
    "                    max_height = cell_height\n",
    "        ws.row_dimensions[row[0].row].height = max_height\n",
    "\n",
    "    wb.save(file_path)\n",
    "\n",
    "print(\"Completed generating answers for all models.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:50:28.662282Z",
     "start_time": "2024-07-26T03:27:28.589570Z"
    }
   },
   "id": "1ca76e1afafc2abf",
   "execution_count": 70
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
