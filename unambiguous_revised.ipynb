{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d450978a0fd1af",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30e6176e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.190218Z",
     "start_time": "2024-07-24T04:10:59.187252Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9ddfedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.410710Z",
     "start_time": "2024-07-24T04:10:59.307193Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b24df538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.423424Z",
     "start_time": "2024-07-24T04:10:59.414016Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42b90774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.727099Z",
     "start_time": "2024-07-24T04:10:59.425506Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_get_text(html_code):\n",
    "    soup = BeautifulSoup(html_code)\n",
    "    return soup.get_text().strip()\n",
    "question_cleaned = df['Question'].apply(my_get_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "390955e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:10:59.773534Z",
     "start_time": "2024-07-24T04:10:59.729942Z"
    }
   },
   "outputs": [],
   "source": [
    "df_noimage_mask = df[~df['Question'].str.contains(\"img\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a23b9a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:11:00.046959Z",
     "start_time": "2024-07-24T04:10:59.775004Z"
    }
   },
   "outputs": [],
   "source": [
    "question_cleaned_noimg = df_noimage_mask['Question'].apply(my_get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc49e8d27a9b58",
   "metadata": {},
   "source": [
    "\n",
    "#### Open Router Question Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4a0a66b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T03:27:22.164721Z",
     "start_time": "2024-07-26T03:27:22.136154Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "# api_key = \"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\"\n",
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b20be57969764df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T04:11:00.071411Z",
     "start_time": "2024-07-24T04:11:00.053792Z"
    }
   },
   "outputs": [],
   "source": [
    "df_50_question = question_cleaned_noimg.sample(n=50,random_state=1)\n",
    "df_50_question.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_50_question.to_csv(\"50_questions.csv\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-07T03:18:37.194258Z",
     "start_time": "2024-08-07T03:18:37.087069Z"
    }
   },
   "id": "4b547ee008e70be8",
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "id": "c9fb03f21f9b31c7",
   "metadata": {},
   "source": [
    "#### API request for specific model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2169d96f4fcdd96b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T03:27:27.470661Z",
     "start_time": "2024-07-26T03:27:27.457686Z"
    }
   },
   "outputs": [],
   "source": [
    "def ask_question_open_router(question,model):\n",
    "    response = requests.post(\n",
    "  url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "  headers={\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"seed\": \"42\",\n",
    "  },\n",
    "  data=json.dumps({\n",
    "    \"model\": model, \n",
    "    \"messages\": [\n",
    "      {\"role\": \"user\", \"content\": question }\n",
    "    ]\n",
    "  })\n",
    ")\n",
    "    response_data = response.json()\n",
    "    messages = [choice['message']['content'] for choice in response_data['choices']]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers for google/gemini-pro...\n",
      "Generating answers for mistralai/mixtral-8x7b-instruct:nitro...\n",
      "Generating answers for mistralai/mistral-7b-instruct:nitro...\n",
      "Completed generating answers for all models.\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    \"openai/gpt-3.5-turbo\",\n",
    "    \"openai/gpt-4\",\n",
    "    \"meta-llama/llama-2-70b-chat\",\n",
    "    \"mistralai/mistral-7b-instruct\",\n",
    "    \"anthropic/claude-3-opus\",\n",
    "    \"google/gemini-pro\",\n",
    "    \"mistralai/mixtral-8x7b-instruct:nitro\",\n",
    "    \"mistralai/mistral-7b-instruct:nitro\"\n",
    "]\n",
    "# Iterate through each model\n",
    "for model in models:\n",
    "    # Create an empty DataFrame to store the results for each model\n",
    "    result = pd.DataFrame(index=range(50), columns=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "    print(f\"Generating answers for {model}...\")\n",
    "\n",
    "    # Generate answers for Q1\n",
    "    for i in range(50):\n",
    "        question = (\"Based on the following multiple-choice question, generate three plausible distractors \"\n",
    "                    \"and one correct answer. Mark the correct answer with an (X), and no explanation \")+ df_50_question[i]\n",
    "        messages = ask_question_open_router(question, model)\n",
    "        result.at[i, 'Q1'] = messages[0]\n",
    "\n",
    "    # Evaluate if the question is unambiguous for Q2\n",
    "    for i in range(50):\n",
    "        question = \"Is the question an unambiguous exam question that has only one answer? \" + df_50_question[i]\n",
    "        messages = ask_question_open_router(question, model)\n",
    "        result.at[i, 'Q2'] = \"Y\" if \"YES\" in messages[0].upper() else \"N\"\n",
    "\n",
    "    # Rephrase ambiguous questions for Q3\n",
    "    for i in range(50):\n",
    "        if result.at[i, 'Q2'] == \"N\":\n",
    "            question = \"How would you rephrase the question to be unambiguous and suitable for a Multiple choice question on an exam? \" + df_50_question[i]\n",
    "            messages = ask_question_open_router(question, model)\n",
    "            result.at[i, 'Q3'] = messages[0]\n",
    "        else:\n",
    "            result.at[i, 'Q3'] = \"None\"\n",
    "\n",
    "    # Generate new answers for rephrased questions for Q4\n",
    "    for i in range(50):\n",
    "        if result.at[i, 'Q3'] != \"None\":\n",
    "            question = ((\"Based on the following multiple-choice question, generate three \"\n",
    "                        \"plausible distractors and one correct answer. Mark the correct answer with an (X), and no explanation \")+ df_50_question[i])\n",
    "            messages = ask_question_open_router(question, model)\n",
    "            result.at[i, 'Q4'] = messages[0]\n",
    "        else:\n",
    "            result.at[i, 'Q4'] = \"None\"\n",
    "\n",
    "    \n",
    "    file_path = os.path.join(output_dir, f\"{model.split('/')[1]}.xlsx\")\n",
    "    result.to_excel(file_path, index=False)\n",
    "\n",
    "    # Adjust column widths\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    for column in ws.columns:\n",
    "        max_length = 0\n",
    "        column_letter = column[0].column_letter  # Get the column letter\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if cell.value:\n",
    "                    max_length = max(max_length, len(str(cell.value)))\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2) * 1.2  # Add some padding\n",
    "        ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "    for row in ws.iter_rows():\n",
    "        max_height = 0\n",
    "        for cell in row:\n",
    "            if cell.value:\n",
    "                lines = str(cell.value).split('\\n')\n",
    "                cell_height = len(lines) * 15  # Approximate row height per line\n",
    "                if cell_height > max_height:\n",
    "                    max_height = cell_height\n",
    "        ws.row_dimensions[row[0].row].height = max_height\n",
    "\n",
    "    wb.save(file_path)\n",
    "\n",
    "print(\"Completed generating answers for all models.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:50:28.662282Z",
     "start_time": "2024-07-26T03:27:28.589570Z"
    }
   },
   "id": "1ca76e1afafc2abf",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "claude3 = pd.read_excel(\"checked/claude3.xlsx\")\n",
    "gemini = pd.read_excel(\"checked/gemini.xlsx\")\n",
    "gpt3 = pd.read_excel(\"checked/gpt3.5.xlsx\")\n",
    "gpt4 = pd.read_excel(\"checked/gpt4.xlsx\")\n",
    "llama = pd.read_excel(\"checked/llama.xlsx\")\n",
    "mistral7bi = pd.read_excel(\"checked/mistral7binstruct.xlsx\")\n",
    "mistral7bin = pd.read_excel(\"checked/mistral7binstructnitro.xlsx\")\n",
    "mistral8x7bin = pd.read_excel(\"checked/mistral8x7binstructnitro.xlsx\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-16T06:46:00.059196Z",
     "start_time": "2024-08-16T06:45:59.905267Z"
    }
   },
   "id": "29e6d60135da021",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Q1 Q2   Q3   Q4\n0   1  N  1.0  1.0\n1   0  N  1.0  0.0\n2   1  N  1.0  1.0\n3   0  Y  NaN  NaN\n4   1  Y  NaN  NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Q1</th>\n      <th>Q2</th>\n      <th>Q3</th>\n      <th>Q4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude3.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-16T06:50:43.589484Z",
     "start_time": "2024-08-16T06:50:43.580776Z"
    }
   },
   "id": "6e26cb8f9288b830",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  claude3              gemini              gpt3.5     ... mistral7bi       \\\n       Q1 Q2   Q3   Q4     Q1 Q2   Q3   Q4     Q1 Q2  ...         Q3   Q4   \n0       1  N  1.0  1.0      1  N  1.0  1.0      0  N  ...        NaN  NaN   \n1       0  N  1.0  0.0      0  N  1.0  0.0      0  Y  ...        1.0  0.0   \n2       1  N  1.0  1.0      1  N  1.0  1.0      0  N  ...        1.0  1.0   \n3       0  Y  NaN  NaN      0  N  1.0  0.0      1  N  ...        1.0  0.0   \n4       1  Y  NaN  NaN      1  N  1.0  1.0      1  Y  ...        1.0  1.0   \n\n  mistral7bin              mistral8x7bin               \n           Q1 Q2   Q3   Q4            Q1 Q2   Q3   Q4  \n0           1  N  1.0  1.0             1  N  1.0  1.0  \n1           1  N  1.0  1.0             0  Y  NaN  NaN  \n2           1  N  1.0  1.0             1  N  1.0  1.0  \n3           0  N  1.0  0.0             0  Y  NaN  NaN  \n4           1  N  1.0  1.0             1  Y  NaN  NaN  \n\n[5 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">claude3</th>\n      <th colspan=\"4\" halign=\"left\">gemini</th>\n      <th colspan=\"2\" halign=\"left\">gpt3.5</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">mistral7bi</th>\n      <th colspan=\"4\" halign=\"left\">mistral7bin</th>\n      <th colspan=\"4\" halign=\"left\">mistral8x7bin</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>Q1</th>\n      <th>Q2</th>\n      <th>Q3</th>\n      <th>Q4</th>\n      <th>Q1</th>\n      <th>Q2</th>\n      <th>Q3</th>\n      <th>Q4</th>\n      <th>Q1</th>\n      <th>Q2</th>\n      <th>...</th>\n      <th>Q3</th>\n      <th>Q4</th>\n      <th>Q1</th>\n      <th>Q2</th>\n      <th>Q3</th>\n      <th>Q4</th>\n      <th>Q1</th>\n      <th>Q2</th>\n      <th>Q3</th>\n      <th>Q4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a multiple models dataframe\n",
    "models = [claude3, gemini, gpt3, gpt4, llama, mistral7bi, mistral7bin, mistral8x7bin]\n",
    "model_names = [\"claude3\", \"gemini\", \"gpt3.5\", \"gpt4\", \"llama\", \"mistral7bi\", \"mistral7bin\", \"mistral8x7bin\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-16T06:47:15.190428Z",
     "start_time": "2024-08-16T06:47:15.160039Z"
    }
   },
   "id": "31a727bdc188a3a8",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "              % Correct % ambiguous %correct after revised\nclaude3            0.64        0.58               0.793103\ngemini             0.56        0.86               0.674419\ngpt3.5             0.64        0.74               0.540541\ngpt4                0.7        0.44               0.818182\nllama              0.62         0.9               0.666667\nmistral7bi          0.5        0.92                    0.5\nmistral7bin        0.56        0.98               0.612245\nmistral8x7bin      0.62        0.68               0.676471",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>% Correct</th>\n      <th>% ambiguous</th>\n      <th>%correct after revised</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>claude3</th>\n      <td>0.64</td>\n      <td>0.58</td>\n      <td>0.793103</td>\n    </tr>\n    <tr>\n      <th>gemini</th>\n      <td>0.56</td>\n      <td>0.86</td>\n      <td>0.674419</td>\n    </tr>\n    <tr>\n      <th>gpt3.5</th>\n      <td>0.64</td>\n      <td>0.74</td>\n      <td>0.540541</td>\n    </tr>\n    <tr>\n      <th>gpt4</th>\n      <td>0.7</td>\n      <td>0.44</td>\n      <td>0.818182</td>\n    </tr>\n    <tr>\n      <th>llama</th>\n      <td>0.62</td>\n      <td>0.9</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>mistral7bi</th>\n      <td>0.5</td>\n      <td>0.92</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>mistral7bin</th>\n      <td>0.56</td>\n      <td>0.98</td>\n      <td>0.612245</td>\n    </tr>\n    <tr>\n      <th>mistral8x7bin</th>\n      <td>0.62</td>\n      <td>0.68</td>\n      <td>0.676471</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_correct = pd.DataFrame(index=model_names,columns=['% Correct','% ambiguous','%correct after revised'])\n",
    "\n",
    "for i in model_names:\n",
    "    model_correct.at[i,'% Correct'] = models[model_names.index(i)]['Q1'].sum()/50\n",
    "    model_correct.at[i,'% ambiguous'] = models[model_names.index(i)]['Q2'].value_counts(normalize=True)['N']\n",
    "    model_correct.at[i,'%correct after revised'] = models[model_names.index(i)]['Q4'].sum()/models[model_names.index(i)]['Q2'].value_counts()['N']\n",
    "\n",
    "model_correct\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-16T06:58:07.445808Z",
     "start_time": "2024-08-16T06:58:07.425430Z"
    }
   },
   "id": "ce8725a12be72bc3",
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6d180205f4c85d64"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
